{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Regression Model in Keras\n",
    "In this course project, you will build a regression model using the deep learning Keras library, and then you will experiment with increasing the number of training epochs and changing number of hidden layers and you will see how changing these parameters impacts the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will be marked by your peers and will be worth 20% of your total grade. The breakdown will be:\n",
    "\n",
    "Part A: 5 marks\n",
    "\n",
    "Part B: 5 marks\n",
    "\n",
    "Part C: 5 marks\n",
    "\n",
    "Part D: 5 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-By-Step Assignment Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Assignment Topic:\n",
    "\n",
    "In this project, you will build a regression model using the Keras library to model the same data about concrete compressive strength that we used in labs 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concrete Data:\n",
    "\n",
    "For your convenience, the data can be found here again: https://cocl.us/concrete_data. To recap, the predictors in the data of concrete strength include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cement\n",
    "2. Blast Furnace Slag\n",
    "3. Fly Ash\n",
    "4. Water\n",
    "5. Superplasticizer\n",
    "6. Coarse Aggregate\n",
    "7. Fine Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Assignment Instructions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Build a baseline model (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train, p_test, t_train, t_test = train_test_split(predictors, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>194.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>165.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>905.9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>631</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>318.8</td>\n",
       "      <td>212.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>852.1</td>\n",
       "      <td>880.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>359.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>942.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>162.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>286.3</td>\n",
       "      <td>200.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>803.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>246.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.1</td>\n",
       "      <td>143.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1086.8</td>\n",
       "      <td>800.9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>190.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>166.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>798.9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>475.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>852.1</td>\n",
       "      <td>781.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "196   194.7                 0.0    100.5  165.6               7.5   \n",
       "631   325.0                 0.0      0.0  184.0               0.0   \n",
       "81    318.8               212.5      0.0  155.7              14.3   \n",
       "526   359.0                19.0    141.0  154.0              10.9   \n",
       "830   162.0               190.0    148.0  179.0              19.0   \n",
       "..      ...                 ...      ...    ...               ...   \n",
       "87    286.3               200.9      0.0  144.7              11.2   \n",
       "330   246.8                 0.0    125.1  143.3              12.0   \n",
       "466   190.3                 0.0    125.2  166.6               9.9   \n",
       "121   475.0               118.8      0.0  181.1               8.9   \n",
       "860   314.0                 0.0    113.0  170.0              10.0   \n",
       "\n",
       "     Coarse Aggregate  Fine Aggregate  Age  \n",
       "196            1006.4           905.9   28  \n",
       "631            1063.0           783.0    7  \n",
       "81              852.1           880.4    3  \n",
       "526             942.0           801.0    3  \n",
       "830             838.0           741.0   28  \n",
       "..                ...             ...  ...  \n",
       "87             1004.6           803.7    3  \n",
       "330            1086.8           800.9   14  \n",
       "466            1079.0           798.9  100  \n",
       "121             852.1           781.5   28  \n",
       "860             925.0           783.0   28  \n",
       "\n",
       "[721 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196    25.72\n",
       "631    17.54\n",
       "81     25.20\n",
       "526    23.64\n",
       "830    33.76\n",
       "       ...  \n",
       "87     24.40\n",
       "330    42.22\n",
       "466    33.56\n",
       "121    68.30\n",
       "860    38.46\n",
       "Name: Strength, Length: 721, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(number_of_hidden_layers=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    for _ in range(number_of_hidden_layers):\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 741778.5000 - val_loss: 354278.8438\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 179133.4531 - val_loss: 30152.4922\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 10652.0801 - val_loss: 4773.3584\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 6647.0928 - val_loss: 3003.5303\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 5091.5654 - val_loss: 2994.8311\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 4586.6699 - val_loss: 2605.4287\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 4234.3901 - val_loss: 2433.7676\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 3875.4778 - val_loss: 2263.9448\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 3544.5422 - val_loss: 2093.1904\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 3231.4602 - val_loss: 1945.9033\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 2950.8416 - val_loss: 1779.7709\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 2700.3447 - val_loss: 1647.3555\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 2456.4365 - val_loss: 1545.5496\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 2241.3755 - val_loss: 1438.6107\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 2050.6543 - val_loss: 1342.8519\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 1873.2642 - val_loss: 1254.7726\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 1713.8285 - val_loss: 1170.5386\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 1565.8025 - val_loss: 1094.8867\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 1435.2780 - val_loss: 1019.4355\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 1318.6255 - val_loss: 984.2589\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 1223.9718 - val_loss: 940.9285\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 1116.0992 - val_loss: 871.3904\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 1028.0238 - val_loss: 821.8444\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 949.8718 - val_loss: 811.0430\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 876.6028 - val_loss: 754.0414\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 810.1269 - val_loss: 719.2759\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 757.1830 - val_loss: 692.1564\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 701.1939 - val_loss: 669.8925\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 653.6518 - val_loss: 660.0724\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 608.9708 - val_loss: 612.0620\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 571.6180 - val_loss: 603.1880\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 531.8746 - val_loss: 592.4164\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 502.5678 - val_loss: 565.2060\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 471.5859 - val_loss: 558.8884\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 447.9319 - val_loss: 522.8094\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 422.4164 - val_loss: 549.7586\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 401.6552 - val_loss: 512.1240\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 380.7872 - val_loss: 496.7071\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 363.8295 - val_loss: 518.9167\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 345.9128 - val_loss: 477.2272\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 330.9486 - val_loss: 488.0052\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 318.2513 - val_loss: 464.8917\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 305.7905 - val_loss: 454.6472\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 294.0929 - val_loss: 463.9361\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 285.8983 - val_loss: 434.9236\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 275.0313 - val_loss: 449.0561\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 267.5375 - val_loss: 423.4172\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 258.6616 - val_loss: 422.3736\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 251.2097 - val_loss: 407.9339\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 245.3187 - val_loss: 403.3968\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = classification_model()\n",
    "\n",
    "history = model.fit(predictors, target, validation_split=0.3, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403.3968200683594"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = history.history['val_loss'][-1]\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 263.0257 - val_loss: 215.7152\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 227.9920 - val_loss: 185.2743\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 218.0305 - val_loss: 173.7897\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 210.0826 - val_loss: 164.1433\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 204.5463 - val_loss: 171.3229\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 201.1040 - val_loss: 162.8923\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 195.3816 - val_loss: 149.7326\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 190.7119 - val_loss: 163.7332\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 188.3505 - val_loss: 148.1870\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 185.9009 - val_loss: 143.4464\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 183.1894 - val_loss: 137.0417\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 182.4208 - val_loss: 138.0639\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 180.3596 - val_loss: 143.8092\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 173.3993 - val_loss: 143.3804\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 171.1282 - val_loss: 161.8365\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 173.0867 - val_loss: 153.8988\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 167.6237 - val_loss: 131.8340\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 162.8537 - val_loss: 155.2043\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 163.7672 - val_loss: 134.8351\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 158.7857 - val_loss: 137.4482\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 157.0730 - val_loss: 136.3219\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 152.4627 - val_loss: 120.3789\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 149.7298 - val_loss: 130.8875\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 146.5230 - val_loss: 136.7273\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 143.3891 - val_loss: 149.2236\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 140.4705 - val_loss: 113.3744\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 135.1951 - val_loss: 120.5853\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 131.2827 - val_loss: 122.4108\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 128.7672 - val_loss: 109.1722\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 125.4925 - val_loss: 104.7971\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 121.2873 - val_loss: 118.1869\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 117.0723 - val_loss: 109.6183\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 113.0109 - val_loss: 101.7259\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 108.3873 - val_loss: 97.5288\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 104.8457 - val_loss: 93.5081\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 103.0409 - val_loss: 92.5159\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 98.3003 - val_loss: 92.2316\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 94.2794 - val_loss: 94.4208\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 92.1423 - val_loss: 85.8383\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 92.0893 - val_loss: 88.9096\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 88.1497 - val_loss: 76.9192\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 86.8039 - val_loss: 84.6726\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 84.1032 - val_loss: 88.1415\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 83.7664 - val_loss: 79.3038\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 83.5454 - val_loss: 82.4264\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 80.5743 - val_loss: 78.8122\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 80.6979 - val_loss: 74.4833\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 81.9639 - val_loss: 82.9472\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 82.9978 - val_loss: 75.1983\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 79.9646 - val_loss: 67.6289\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 16104.1953 - val_loss: 2486.3401\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 2861.1882 - val_loss: 1016.1570\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 1364.4110 - val_loss: 643.2267\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 721.3986 - val_loss: 353.1776\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 465.6609 - val_loss: 271.2816\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 384.0836 - val_loss: 210.6135\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 339.2454 - val_loss: 201.7579\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 311.8030 - val_loss: 192.3364\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 290.9045 - val_loss: 182.5115\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 276.9912 - val_loss: 206.5961\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 270.4379 - val_loss: 195.2140\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 255.1063 - val_loss: 158.3964\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 251.5155 - val_loss: 160.4819\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 245.4677 - val_loss: 153.6136\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 236.3981 - val_loss: 146.5198\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 230.2966 - val_loss: 139.3926\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 227.7103 - val_loss: 133.2866\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 222.8393 - val_loss: 130.8506\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 218.1618 - val_loss: 121.1546\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 224.5114 - val_loss: 121.6141\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 216.8633 - val_loss: 134.8185\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 210.5594 - val_loss: 114.7381\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 215.2342 - val_loss: 114.1879\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 206.5494 - val_loss: 107.6823\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 204.6360 - val_loss: 113.5339\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 201.3683 - val_loss: 108.8087\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 199.4580 - val_loss: 110.9793\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 199.0266 - val_loss: 125.1402\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 202.8213 - val_loss: 122.1623\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 194.3571 - val_loss: 108.0225\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 190.1784 - val_loss: 111.3507\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 187.0731 - val_loss: 123.8513\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 184.1126 - val_loss: 123.1026\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 182.2460 - val_loss: 142.6116\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 187.9194 - val_loss: 101.5155\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 175.9817 - val_loss: 100.4563\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 167.8050 - val_loss: 110.0197\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 161.1333 - val_loss: 103.6282\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 156.5918 - val_loss: 122.6496\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 154.9284 - val_loss: 104.6005\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 153.1811 - val_loss: 132.4697\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 155.7361 - val_loss: 100.6376\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 152.6100 - val_loss: 132.5262\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 147.6822 - val_loss: 101.1724\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 147.5463 - val_loss: 137.8176\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 144.9283 - val_loss: 137.5623\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 141.7637 - val_loss: 113.1734\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 137.3586 - val_loss: 108.1006\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 138.9893 - val_loss: 120.8269\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 132.9732 - val_loss: 136.2661\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 204962.8438 - val_loss: 61571.2305\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 25661.7305 - val_loss: 3367.0579\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 1900.2908 - val_loss: 2963.0208\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 1716.7274 - val_loss: 2344.4170\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 1420.9176 - val_loss: 2006.5853\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 1309.1538 - val_loss: 1851.9236\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 1190.5077 - val_loss: 1683.6849\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 1077.9233 - val_loss: 1472.0627\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 973.2707 - val_loss: 1280.4165\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 880.6759 - val_loss: 1137.4056\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 802.6550 - val_loss: 1022.7128\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 743.1516 - val_loss: 908.1010\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 698.0452 - val_loss: 840.9313\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 661.7828 - val_loss: 769.2562\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 632.3026 - val_loss: 710.5139\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 601.5840 - val_loss: 662.0679\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 576.3494 - val_loss: 624.3137\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 554.7055 - val_loss: 581.5864\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 532.0998 - val_loss: 538.9727\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 513.5582 - val_loss: 529.1862\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 494.3347 - val_loss: 485.4783\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 476.8980 - val_loss: 453.6006\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 460.5593 - val_loss: 444.7087\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 446.6392 - val_loss: 409.1487\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 431.8336 - val_loss: 384.1071\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 419.2754 - val_loss: 371.9725\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 406.5891 - val_loss: 347.6044\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 397.5004 - val_loss: 342.3740\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 383.5148 - val_loss: 318.7981\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 373.1374 - val_loss: 311.2681\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 361.9875 - val_loss: 289.8337\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 353.9269 - val_loss: 295.8696\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 343.2605 - val_loss: 261.6904\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 337.1875 - val_loss: 281.7355\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 327.8264 - val_loss: 250.8022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 318.8294 - val_loss: 228.4406\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 311.4042 - val_loss: 235.4987\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 303.2945 - val_loss: 219.6166\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 295.4662 - val_loss: 212.0551\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 289.9875 - val_loss: 198.0489\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 281.3578 - val_loss: 216.8077\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 277.8694 - val_loss: 206.7755\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 269.4404 - val_loss: 196.4112\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 264.4266 - val_loss: 180.1418\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 260.4202 - val_loss: 203.6991\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 254.1015 - val_loss: 180.5992\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 248.7690 - val_loss: 166.9274\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 249.0365 - val_loss: 180.5292\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 241.9357 - val_loss: 165.8226\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 235.8055 - val_loss: 163.8498\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 22352.6250 - val_loss: 11730.6924\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 7741.4883 - val_loss: 4413.6328\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 3273.4736 - val_loss: 3468.2000\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 2688.8975 - val_loss: 2886.9426\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 2262.1804 - val_loss: 2449.2656\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 1909.0219 - val_loss: 2105.2959\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 1627.3048 - val_loss: 1789.0382\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 1379.7354 - val_loss: 1472.7295\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 1170.2815 - val_loss: 1216.5167\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 1000.4458 - val_loss: 1036.5994\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 882.3228 - val_loss: 886.8656\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 800.1434 - val_loss: 782.3728\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 744.1005 - val_loss: 703.7572\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 695.4881 - val_loss: 635.3726\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 654.0693 - val_loss: 592.7850\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 616.0405 - val_loss: 544.2593\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 576.2813 - val_loss: 508.9844\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 542.1390 - val_loss: 466.4760\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 511.4884 - val_loss: 435.2053\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 483.6607 - val_loss: 399.0065\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 454.9431 - val_loss: 360.0565\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 430.0782 - val_loss: 329.5604\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 403.0267 - val_loss: 293.5735\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 379.6449 - val_loss: 260.6515\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 356.3445 - val_loss: 238.9354\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 334.8068 - val_loss: 216.1933\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 315.9650 - val_loss: 201.4187\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 300.3620 - val_loss: 190.5514\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 284.2548 - val_loss: 172.4055\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 270.2965 - val_loss: 172.1887\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 259.0212 - val_loss: 148.6342\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 247.8792 - val_loss: 163.2365\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 238.0844 - val_loss: 151.0328\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 231.9557 - val_loss: 133.3405\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 219.8675 - val_loss: 121.7964\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 211.3544 - val_loss: 140.0345\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 202.1697 - val_loss: 116.1653\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 196.1580 - val_loss: 119.9992\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 189.3687 - val_loss: 122.6259\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 181.8190 - val_loss: 111.3129\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 176.9142 - val_loss: 99.5709\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 172.8115 - val_loss: 121.8814\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 166.8216 - val_loss: 101.6867\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 160.8849 - val_loss: 99.8765\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 157.9821 - val_loss: 98.1906\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 153.3423 - val_loss: 92.9103\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 148.9707 - val_loss: 104.1447\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 147.6352 - val_loss: 95.9115\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 142.7968 - val_loss: 86.9234\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 140.5254 - val_loss: 82.9641\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 208785.8125 - val_loss: 79309.2031\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 45960.3555 - val_loss: 8412.2236\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 7196.2227 - val_loss: 1934.1666\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 3743.0308 - val_loss: 2165.4209\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 3208.6641 - val_loss: 1746.9261\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 2730.9507 - val_loss: 1412.4937\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 2335.5225 - val_loss: 1216.2273\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 2030.7561 - val_loss: 1064.2191\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 1766.3585 - val_loss: 935.6245\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 1560.3981 - val_loss: 845.8015\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 1394.4923 - val_loss: 764.5565\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 1261.2440 - val_loss: 715.4494\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 1162.7599 - val_loss: 670.1230\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 1082.6481 - val_loss: 641.1386\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 1019.5310 - val_loss: 612.3226\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 966.5721 - val_loss: 611.9580\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 923.5650 - val_loss: 572.7681\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 887.3925 - val_loss: 569.9515\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 858.0551 - val_loss: 559.9203\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 832.7910 - val_loss: 549.5532\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 811.5605 - val_loss: 551.9875\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 789.9257 - val_loss: 526.4054\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 770.8354 - val_loss: 545.6316\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 753.3961 - val_loss: 532.5452\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 738.2694 - val_loss: 534.6639\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 723.3384 - val_loss: 528.9748\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 709.6688 - val_loss: 523.2003\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 696.9283 - val_loss: 515.3879\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 685.7874 - val_loss: 518.3063\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 674.9877 - val_loss: 497.1680\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 664.2690 - val_loss: 510.1181\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 655.0060 - val_loss: 517.2507\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 644.6944 - val_loss: 491.8648\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 636.8594 - val_loss: 496.2369\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 627.3348 - val_loss: 484.8087\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 618.8635 - val_loss: 492.6655\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 610.8783 - val_loss: 496.3752\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 603.2372 - val_loss: 478.2610\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 596.7583 - val_loss: 473.7317\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 588.9084 - val_loss: 470.2993\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 582.3290 - val_loss: 462.4696\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 575.0932 - val_loss: 473.9456\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 570.8549 - val_loss: 458.4791\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 561.2902 - val_loss: 465.5323\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 556.1513 - val_loss: 453.7330\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 547.7568 - val_loss: 446.9918\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 541.0083 - val_loss: 440.5316\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 536.0187 - val_loss: 451.3073\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 529.1865 - val_loss: 434.7683\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 522.5980 - val_loss: 432.7090\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 18048.7344 - val_loss: 13835.0967\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 7514.0464 - val_loss: 11734.2227\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 5438.4863 - val_loss: 8835.5195\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 4371.1621 - val_loss: 7021.1587\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 3595.6758 - val_loss: 5595.3457\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 2949.2539 - val_loss: 4577.9468\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 2402.4751 - val_loss: 3520.3337\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 1964.8165 - val_loss: 2743.4922\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 1585.7759 - val_loss: 2089.7368\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 1295.7324 - val_loss: 1581.0770\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 1014.5198 - val_loss: 1232.9608\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 795.3033 - val_loss: 876.0215\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 617.4871 - val_loss: 641.9811\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 472.3341 - val_loss: 446.5444\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 355.4184 - val_loss: 356.8468\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 287.1022 - val_loss: 290.7341\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 233.2003 - val_loss: 200.0554\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 197.0030 - val_loss: 161.2619\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 176.2643 - val_loss: 152.0567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 156.9849 - val_loss: 147.4167\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 148.3490 - val_loss: 155.1842\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 143.4302 - val_loss: 157.1603\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 140.3721 - val_loss: 152.7765\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 140.3168 - val_loss: 171.4224\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 138.3065 - val_loss: 178.2561\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 136.9516 - val_loss: 151.9977\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 134.2310 - val_loss: 144.9882\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 139.4535 - val_loss: 143.8331\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 137.9500 - val_loss: 192.5611\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 141.6259 - val_loss: 135.7545\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 132.2956 - val_loss: 136.5634\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 140.0877 - val_loss: 132.9626\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 132.9153 - val_loss: 139.6146\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 128.9726 - val_loss: 146.2348\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 127.4742 - val_loss: 133.0620\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 129.5275 - val_loss: 149.2719\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 129.4891 - val_loss: 125.4840\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 128.1918 - val_loss: 148.2160\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 126.4423 - val_loss: 119.8096\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 125.4460 - val_loss: 119.2748\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 124.9415 - val_loss: 126.0841\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 122.0161 - val_loss: 128.1040\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 121.8947 - val_loss: 133.0973\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 120.5303 - val_loss: 117.5691\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 124.6255 - val_loss: 113.0568\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 123.0755 - val_loss: 116.7203\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 121.2210 - val_loss: 111.7642\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 121.8088 - val_loss: 119.2833\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 119.5584 - val_loss: 117.7896\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 120.4505 - val_loss: 113.4759\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 6179.2192 - val_loss: 2299.5667\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 1461.5177 - val_loss: 1272.7510\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 948.4239 - val_loss: 1092.0261\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 735.7622 - val_loss: 884.9397\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 590.9762 - val_loss: 720.4689\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 483.9788 - val_loss: 570.3985\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 401.2007 - val_loss: 464.0428\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 332.9096 - val_loss: 357.5505\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 277.4514 - val_loss: 293.9315\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 232.1610 - val_loss: 219.1237\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 197.6490 - val_loss: 211.6211\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 169.4499 - val_loss: 156.2546\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 146.8952 - val_loss: 107.0296\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 128.8994 - val_loss: 99.9749\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 119.4021 - val_loss: 86.6518\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 109.4360 - val_loss: 70.9221\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 103.5800 - val_loss: 79.1801\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 101.2185 - val_loss: 66.8285\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 98.0317 - val_loss: 66.3527\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 96.6558 - val_loss: 65.4565\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 95.0172 - val_loss: 65.8045\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 95.4322 - val_loss: 65.1774\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 93.6794 - val_loss: 67.9031\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 94.6371 - val_loss: 64.9234\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 91.7295 - val_loss: 65.8230\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 93.4860 - val_loss: 65.6613\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 92.4158 - val_loss: 68.2104\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 89.2012 - val_loss: 66.1951\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 88.6520 - val_loss: 67.2523\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 88.5525 - val_loss: 66.6166\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 88.8815 - val_loss: 65.9296\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 90.3304 - val_loss: 68.0390\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 86.4992 - val_loss: 71.3800\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 87.8002 - val_loss: 68.2697\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 87.8303 - val_loss: 65.7139\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 85.8050 - val_loss: 66.7942\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 85.2000 - val_loss: 72.0109\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 87.4010 - val_loss: 65.1331\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 86.5474 - val_loss: 66.9521\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 85.1692 - val_loss: 81.1788\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 88.4886 - val_loss: 65.1861\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 83.8375 - val_loss: 68.0247\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 83.7731 - val_loss: 69.0283\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 85.0929 - val_loss: 66.1377\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 83.7245 - val_loss: 67.5658\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 83.9767 - val_loss: 68.7673\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 84.1701 - val_loss: 67.3557\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 83.5355 - val_loss: 66.3488\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 86.2110 - val_loss: 66.3682\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 83.2661 - val_loss: 70.1259\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 105774.6797 - val_loss: 63720.3438\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 54783.0508 - val_loss: 32996.5938\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 29280.3965 - val_loss: 18912.7559\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 18102.5273 - val_loss: 12881.4766\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 12736.3838 - val_loss: 9300.7188\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 9386.6641 - val_loss: 7022.2783\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 7368.0845 - val_loss: 5660.5361\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 6143.8086 - val_loss: 4753.2568\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 5268.9966 - val_loss: 4069.3333\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 4581.8101 - val_loss: 3530.6670\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 4032.6938 - val_loss: 3084.6448\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 3575.8022 - val_loss: 2728.4768\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 3194.4802 - val_loss: 2437.7021\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 2872.2625 - val_loss: 2192.0391\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 2600.7402 - val_loss: 1980.3347\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 2377.0481 - val_loss: 1804.2245\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 2196.0823 - val_loss: 1653.9956\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 2053.1929 - val_loss: 1537.9225\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 1948.6940 - val_loss: 1451.2540\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 1872.5223 - val_loss: 1388.5869\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 1817.9164 - val_loss: 1345.8059\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 1780.4789 - val_loss: 1318.3232\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 1755.3206 - val_loss: 1300.2355\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 1739.5776 - val_loss: 1286.8596\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 1728.4075 - val_loss: 1277.3508\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 1720.2504 - val_loss: 1269.6653\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 1713.5900 - val_loss: 1262.9077\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 1707.9918 - val_loss: 1257.2213\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 1703.4329 - val_loss: 1252.0645\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 1699.5350 - val_loss: 1247.5948\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 1696.2971 - val_loss: 1243.6473\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 1693.6655 - val_loss: 1240.2122\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 1691.3560 - val_loss: 1237.0475\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 1689.2866 - val_loss: 1234.1475\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 1687.3713 - val_loss: 1231.7836\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 1685.6378 - val_loss: 1229.6558\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 1684.0330 - val_loss: 1227.6130\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 1682.5271 - val_loss: 1225.8672\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 1681.0793 - val_loss: 1224.1306\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 1679.6881 - val_loss: 1222.4200\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 1678.3354 - val_loss: 1220.7601\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 1677.0280 - val_loss: 1219.2084\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 1675.7800 - val_loss: 1217.7711\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 1674.5767 - val_loss: 1216.3848\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 1673.3656 - val_loss: 1215.1160\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 1672.1860 - val_loss: 1213.8214\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 1671.0135 - val_loss: 1212.5182\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 1669.8365 - val_loss: 1211.3069\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 1668.6924 - val_loss: 1210.0133\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 1667.5413 - val_loss: 1208.7756\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 46801.6914 - val_loss: 16842.6562\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 8671.7861 - val_loss: 1826.4790\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 1367.9807 - val_loss: 1581.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 1238.1173 - val_loss: 1290.1295\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 1109.0927 - val_loss: 1134.6658\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 1052.6129 - val_loss: 1051.8906\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 987.6514 - val_loss: 982.8220\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 929.7112 - val_loss: 909.5162\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 873.4098 - val_loss: 822.8059\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 817.6308 - val_loss: 780.4646\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 751.2393 - val_loss: 716.1453\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 689.9584 - val_loss: 650.0869\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 628.3169 - val_loss: 587.5564\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 572.6119 - val_loss: 508.1401\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 517.3846 - val_loss: 451.5414\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 466.4947 - val_loss: 484.0857\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 421.8880 - val_loss: 354.0492\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 384.5851 - val_loss: 319.8900\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 344.9807 - val_loss: 285.2241\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 315.8385 - val_loss: 279.3222\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 291.4867 - val_loss: 256.2038\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 272.2619 - val_loss: 208.3276\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 257.3951 - val_loss: 247.1695\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 247.1787 - val_loss: 258.6933\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 238.8242 - val_loss: 209.8993\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 227.0199 - val_loss: 164.9321\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 221.5845 - val_loss: 167.9375\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 219.7796 - val_loss: 215.9044\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 212.8413 - val_loss: 180.0514\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 207.9007 - val_loss: 144.6647\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 203.8031 - val_loss: 156.9804\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 197.6946 - val_loss: 133.7667\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 195.8262 - val_loss: 153.9826\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 192.2640 - val_loss: 144.3013\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 186.2026 - val_loss: 124.4975\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 184.4917 - val_loss: 118.3608\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 181.2304 - val_loss: 115.1999\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 182.1661 - val_loss: 137.9694\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 177.5744 - val_loss: 103.9950\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 174.9987 - val_loss: 116.0870\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 171.0481 - val_loss: 128.6161\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 169.8101 - val_loss: 105.1715\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 163.9669 - val_loss: 112.5318\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 160.9282 - val_loss: 101.9665\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 160.5264 - val_loss: 105.3928\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 154.7693 - val_loss: 128.7617\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 155.8954 - val_loss: 106.4453\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 151.7746 - val_loss: 100.1422\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 156.4973 - val_loss: 94.5591\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 148.3612 - val_loss: 115.9597\n",
      "Epoch 1/50\n",
      "23/23 - 1s - loss: 2642.2869 - val_loss: 1428.5433\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 1872.0536 - val_loss: 1092.9452\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 1496.9913 - val_loss: 869.6772\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 1207.8529 - val_loss: 683.4625\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 972.6613 - val_loss: 536.0076\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 771.6704 - val_loss: 404.9471\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 588.0003 - val_loss: 303.8254\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 454.3391 - val_loss: 235.3436\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 369.0991 - val_loss: 192.3330\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 309.3933 - val_loss: 165.4322\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 267.4334 - val_loss: 151.1278\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 239.0558 - val_loss: 143.4104\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 220.3782 - val_loss: 129.2183\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 199.3349 - val_loss: 118.4716\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 187.1681 - val_loss: 113.4386\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 175.4563 - val_loss: 108.9085\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 164.7115 - val_loss: 113.5618\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 156.4718 - val_loss: 86.2025\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 149.3511 - val_loss: 79.1408\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 142.1024 - val_loss: 88.6275\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 136.3400 - val_loss: 78.4116\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 132.1291 - val_loss: 71.8855\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 129.0605 - val_loss: 73.6542\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 124.4960 - val_loss: 77.7589\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 122.9856 - val_loss: 88.8118\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 120.5158 - val_loss: 71.3004\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 118.5737 - val_loss: 69.9671\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 116.5126 - val_loss: 70.0476\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 117.5922 - val_loss: 74.8110\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 115.5106 - val_loss: 77.2833\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 112.9847 - val_loss: 83.4134\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 111.3242 - val_loss: 79.3449\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 111.0943 - val_loss: 78.3888\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 109.7876 - val_loss: 91.6732\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 111.2735 - val_loss: 76.2126\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 109.9264 - val_loss: 69.4418\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 110.6228 - val_loss: 69.1788\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 108.9140 - val_loss: 79.9949\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 109.8669 - val_loss: 69.2199\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 108.1394 - val_loss: 84.1865\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 105.8179 - val_loss: 72.7096\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 104.3322 - val_loss: 67.5189\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 106.3557 - val_loss: 69.3696\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 105.7326 - val_loss: 70.0917\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 103.4060 - val_loss: 75.7050\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 103.0728 - val_loss: 71.3949\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 102.5321 - val_loss: 76.6645\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 101.0350 - val_loss: 75.1775\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 101.0910 - val_loss: 65.0969\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 101.7542 - val_loss: 75.6984\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 3060.2756 - val_loss: 2208.6963\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 1076.7216 - val_loss: 1650.9821\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 773.2451 - val_loss: 1047.8009\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 563.4766 - val_loss: 728.0844\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 445.3892 - val_loss: 526.7077\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 369.9739 - val_loss: 397.0862\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 315.0704 - val_loss: 315.1371\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 278.1599 - val_loss: 258.9891\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 247.8251 - val_loss: 217.0554\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 225.0505 - val_loss: 197.4683\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 209.3568 - val_loss: 169.4788\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 194.6779 - val_loss: 164.0748\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 180.4623 - val_loss: 140.5999\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 173.8290 - val_loss: 134.9891\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 164.1868 - val_loss: 127.1718\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 158.0735 - val_loss: 122.3527\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 152.8953 - val_loss: 118.8025\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 148.7444 - val_loss: 113.7567\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 145.3043 - val_loss: 111.5855\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 142.6826 - val_loss: 109.5017\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 138.6142 - val_loss: 109.0195\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 136.3161 - val_loss: 103.6194\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 135.5303 - val_loss: 102.3424\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 134.3161 - val_loss: 108.8899\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 130.6705 - val_loss: 100.3958\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 128.5520 - val_loss: 100.5146\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 126.6997 - val_loss: 97.3485\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 124.6561 - val_loss: 98.2317\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 122.7679 - val_loss: 93.5556\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 122.1172 - val_loss: 96.2882\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 120.1508 - val_loss: 92.7299\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 119.0863 - val_loss: 92.1087\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 117.5743 - val_loss: 93.9577\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 116.5192 - val_loss: 89.4717\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 114.4251 - val_loss: 88.4471\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 115.2784 - val_loss: 92.2059\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 112.7866 - val_loss: 85.4236\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 110.6873 - val_loss: 83.9876\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 0s - loss: 109.8518 - val_loss: 84.9034\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 108.2628 - val_loss: 86.6326\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 107.2922 - val_loss: 81.6542\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 107.3212 - val_loss: 81.3113\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 105.2628 - val_loss: 80.7003\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 103.6167 - val_loss: 80.8068\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 102.5872 - val_loss: 81.0290\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 101.8534 - val_loss: 81.2880\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 100.7937 - val_loss: 83.7342\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 102.1872 - val_loss: 80.7075\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 98.8853 - val_loss: 76.4317\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 97.8990 - val_loss: 77.5146\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 1729.9454 - val_loss: 390.5802\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 395.2162 - val_loss: 351.6808\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 335.8435 - val_loss: 314.0500\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 311.7326 - val_loss: 308.1620\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 289.8962 - val_loss: 298.9060\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 274.1052 - val_loss: 290.4227\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 260.9646 - val_loss: 286.6894\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 250.8438 - val_loss: 275.2782\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 241.6953 - val_loss: 271.2362\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 232.7724 - val_loss: 255.0780\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 224.8487 - val_loss: 241.4915\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 212.5824 - val_loss: 219.7027\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 198.4764 - val_loss: 189.3376\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 178.4259 - val_loss: 147.5404\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 162.2469 - val_loss: 118.5585\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 150.4019 - val_loss: 101.7881\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 144.6396 - val_loss: 93.7585\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 139.7706 - val_loss: 89.0339\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 134.1488 - val_loss: 88.7638\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 131.5574 - val_loss: 96.1660\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 129.5515 - val_loss: 84.7187\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 126.7486 - val_loss: 84.7313\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 123.6009 - val_loss: 81.4318\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 121.3286 - val_loss: 82.7079\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 118.4663 - val_loss: 86.7485\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 118.8529 - val_loss: 84.6809\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 115.9748 - val_loss: 85.2928\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 115.3102 - val_loss: 92.0032\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 114.7160 - val_loss: 104.5061\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 115.1779 - val_loss: 90.1006\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 111.3069 - val_loss: 87.4417\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 111.8340 - val_loss: 87.9217\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 113.9046 - val_loss: 87.9843\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 108.5769 - val_loss: 86.5801\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 107.2085 - val_loss: 87.9803\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 107.4073 - val_loss: 87.0574\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 108.0148 - val_loss: 86.9837\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 106.8521 - val_loss: 86.8177\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 105.3282 - val_loss: 86.7469\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 104.2635 - val_loss: 85.1872\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 105.3854 - val_loss: 85.5181\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 104.8875 - val_loss: 94.8524\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 109.3114 - val_loss: 83.3299\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 104.7139 - val_loss: 88.3981\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 103.0347 - val_loss: 89.3893\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 106.0525 - val_loss: 84.6229\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 102.9488 - val_loss: 85.0786\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 98.1099 - val_loss: 86.2727\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 99.0048 - val_loss: 82.6537\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 98.6280 - val_loss: 83.5362\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 21439.9570 - val_loss: 11936.1270\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 10518.8291 - val_loss: 7069.4609\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 7172.7939 - val_loss: 5080.2017\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 5405.4004 - val_loss: 3887.6885\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 4296.1069 - val_loss: 3113.7800\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 3551.3225 - val_loss: 2570.8730\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 3015.5049 - val_loss: 2168.8342\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 2591.9102 - val_loss: 1839.5406\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 2209.6431 - val_loss: 1541.9116\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 1881.1635 - val_loss: 1335.6754\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 1708.6078 - val_loss: 1211.8754\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 1609.5569 - val_loss: 1126.3009\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 1520.9750 - val_loss: 1047.5610\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 1424.5618 - val_loss: 960.9788\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 1313.2502 - val_loss: 860.6281\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 1182.5946 - val_loss: 748.1478\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 1033.3058 - val_loss: 620.5638\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 866.0623 - val_loss: 481.3916\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 684.9088 - val_loss: 349.7537\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 517.9204 - val_loss: 239.1316\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 386.2362 - val_loss: 177.4649\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 309.4121 - val_loss: 160.8411\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 277.8769 - val_loss: 164.8337\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 270.3430 - val_loss: 171.1862\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 268.2315 - val_loss: 172.2787\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 267.2469 - val_loss: 172.1792\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 266.4526 - val_loss: 171.8481\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 265.7599 - val_loss: 172.5990\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 264.6463 - val_loss: 170.1498\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 263.6584 - val_loss: 170.8029\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 262.7511 - val_loss: 169.9959\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 261.8666 - val_loss: 169.4050\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 260.8912 - val_loss: 170.4157\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 259.9113 - val_loss: 169.8223\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 259.0131 - val_loss: 169.4671\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 258.0085 - val_loss: 168.1088\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 257.1144 - val_loss: 168.1496\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 255.9839 - val_loss: 167.1022\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 254.9478 - val_loss: 166.8033\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 253.9748 - val_loss: 165.7823\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 252.9474 - val_loss: 165.6370\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 251.7361 - val_loss: 166.4729\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 250.7658 - val_loss: 166.3759\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 249.6940 - val_loss: 164.8173\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 249.2051 - val_loss: 161.8936\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 247.4912 - val_loss: 164.7302\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 246.2244 - val_loss: 162.7293\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 245.1491 - val_loss: 160.2375\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 243.9350 - val_loss: 161.9129\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 242.5315 - val_loss: 160.1811\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "for _ in range(50):\n",
    "    model = classification_model()\n",
    "    mses.append(model.fit(predictors, target, validation_split=0.3, epochs=50, verbose=2).history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.08843309052136"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "mean_mses = statistics.mean(mses)\n",
    "mean_mses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Normalize the data (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "**How does the mean of the mean squared errors compare to that from Step A?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 1638.6543 - val_loss: 1135.2166\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 1489.4409 - val_loss: 992.2640\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 1290.2433 - val_loss: 825.8729\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 1063.8208 - val_loss: 663.6851\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 838.8440 - val_loss: 525.3444\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 642.8145 - val_loss: 420.8675\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 482.3181 - val_loss: 348.7704\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 373.5791 - val_loss: 304.1924\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 307.2779 - val_loss: 275.7570\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 270.2526 - val_loss: 258.1033\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 249.0557 - val_loss: 246.3729\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 236.4117 - val_loss: 236.9051\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 226.6402 - val_loss: 227.7021\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 219.0582 - val_loss: 220.4647\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 212.7766 - val_loss: 213.4995\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 207.3124 - val_loss: 208.0290\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 202.6222 - val_loss: 201.6946\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 198.3753 - val_loss: 196.6693\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 194.5508 - val_loss: 192.9703\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 190.7846 - val_loss: 188.7745\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 187.8963 - val_loss: 185.6683\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 184.5413 - val_loss: 181.7902\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 181.8781 - val_loss: 179.3656\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 179.2201 - val_loss: 177.0212\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 176.5433 - val_loss: 173.5435\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 174.1308 - val_loss: 171.3654\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 171.7117 - val_loss: 169.3430\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 169.7144 - val_loss: 167.3273\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 167.5881 - val_loss: 166.7215\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 165.9468 - val_loss: 164.5439\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 163.7556 - val_loss: 162.7509\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 162.1362 - val_loss: 161.1493\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 160.4420 - val_loss: 159.2404\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 158.6680 - val_loss: 157.8775\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 157.0525 - val_loss: 156.5465\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 155.7353 - val_loss: 155.7582\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 154.5587 - val_loss: 154.6991\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 152.5612 - val_loss: 153.2755\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 151.4603 - val_loss: 152.3913\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 150.1111 - val_loss: 150.9543\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 148.8198 - val_loss: 150.0897\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 147.6351 - val_loss: 149.9015\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 146.3777 - val_loss: 148.5221\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 145.4916 - val_loss: 147.5506\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 144.1230 - val_loss: 145.7682\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 143.0349 - val_loss: 144.3990\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 142.1507 - val_loss: 144.2432\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 141.2200 - val_loss: 142.8570\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 140.0766 - val_loss: 142.7341\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 139.2045 - val_loss: 141.3270\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 138.4037 - val_loss: 141.3921\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 137.4395 - val_loss: 140.2619\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 136.7242 - val_loss: 139.6178\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 136.1787 - val_loss: 138.6305\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 135.1131 - val_loss: 137.7373\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 134.5888 - val_loss: 136.7036\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 133.6313 - val_loss: 136.1240\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 132.8849 - val_loss: 136.1752\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 132.3539 - val_loss: 135.4477\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 131.4960 - val_loss: 135.3211\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 130.8562 - val_loss: 134.8088\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 130.2366 - val_loss: 133.7432\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 129.6292 - val_loss: 133.5970\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 129.1584 - val_loss: 132.4379\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 128.4419 - val_loss: 131.6926\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 127.8823 - val_loss: 131.3986\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 127.4015 - val_loss: 131.2585\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 126.8201 - val_loss: 129.9138\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 126.3199 - val_loss: 128.5603\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 125.8264 - val_loss: 129.1518\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 125.1990 - val_loss: 128.7970\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 124.6467 - val_loss: 128.1618\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 124.5706 - val_loss: 128.0216\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 123.7209 - val_loss: 127.2928\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 123.2286 - val_loss: 126.9792\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 122.8152 - val_loss: 126.6578\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 122.3992 - val_loss: 126.8860\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 121.9346 - val_loss: 125.7683\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 121.5539 - val_loss: 125.5965\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 121.3029 - val_loss: 124.7382\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 120.8570 - val_loss: 124.9646\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 120.4450 - val_loss: 124.2976\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 120.1457 - val_loss: 123.6060\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 119.7845 - val_loss: 124.3066\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 119.3471 - val_loss: 122.4429\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 119.0142 - val_loss: 122.2310\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 118.6603 - val_loss: 121.9885\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 118.2687 - val_loss: 122.1514\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 117.9255 - val_loss: 121.6310\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 117.6607 - val_loss: 121.0931\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 117.3245 - val_loss: 121.0506\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 117.1523 - val_loss: 121.3982\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 116.6487 - val_loss: 120.7108\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 116.3410 - val_loss: 119.7925\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 115.8814 - val_loss: 120.0989\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 115.5917 - val_loss: 118.2293\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 115.2936 - val_loss: 117.7468\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 114.9250 - val_loss: 118.6422\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 114.7128 - val_loss: 117.9561\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 114.3891 - val_loss: 117.9307\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 113.9813 - val_loss: 117.5381\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 113.5668 - val_loss: 116.4392\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 113.3792 - val_loss: 116.2853\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 113.1444 - val_loss: 116.5208\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 112.7113 - val_loss: 116.0698\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 112.3407 - val_loss: 116.5752\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 112.1362 - val_loss: 116.5275\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 111.7486 - val_loss: 115.1573\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 111.5853 - val_loss: 115.0176\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 111.1118 - val_loss: 114.4818\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 110.8668 - val_loss: 115.1870\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 110.5500 - val_loss: 114.8250\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 110.5597 - val_loss: 114.2701\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 109.9195 - val_loss: 113.2107\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 109.7054 - val_loss: 114.0959\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 109.3094 - val_loss: 112.6826\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 109.1344 - val_loss: 113.4080\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 108.7518 - val_loss: 112.9003\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 108.3803 - val_loss: 113.3741\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 108.3036 - val_loss: 113.0907\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 107.8879 - val_loss: 113.0386\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 107.5253 - val_loss: 113.0101\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 107.3038 - val_loss: 111.5623\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 107.0172 - val_loss: 112.1736\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 106.6601 - val_loss: 112.8568\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 106.5041 - val_loss: 112.3752\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 106.1749 - val_loss: 112.0699\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 106.0165 - val_loss: 112.3439\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 105.7677 - val_loss: 112.0908\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 105.3528 - val_loss: 111.8603\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 105.1581 - val_loss: 111.0710\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 104.9042 - val_loss: 111.6806\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 104.6081 - val_loss: 111.9749\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 104.3588 - val_loss: 110.5298\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 104.0950 - val_loss: 111.5010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 103.7666 - val_loss: 111.1153\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 103.7094 - val_loss: 111.4944\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 103.2196 - val_loss: 111.2564\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 102.9822 - val_loss: 110.5969\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 102.8767 - val_loss: 110.6945\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 102.5226 - val_loss: 110.7307\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 102.2388 - val_loss: 110.1290\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 102.1406 - val_loss: 110.0521\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 101.8300 - val_loss: 110.0107\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 101.4843 - val_loss: 109.6741\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 101.2472 - val_loss: 110.0469\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 101.0670 - val_loss: 111.3422\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 100.9991 - val_loss: 110.3063\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 100.5489 - val_loss: 110.5194\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 100.4023 - val_loss: 109.1801\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 100.0513 - val_loss: 110.0727\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 99.7940 - val_loss: 110.6266\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 99.7208 - val_loss: 110.9079\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 99.4234 - val_loss: 110.9132\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 99.1628 - val_loss: 110.0106\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 98.9292 - val_loss: 110.0244\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 98.7981 - val_loss: 111.4433\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 98.5910 - val_loss: 110.7114\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 98.1795 - val_loss: 108.9711\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 98.0402 - val_loss: 109.2082\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 97.8056 - val_loss: 109.5672\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 97.6000 - val_loss: 109.6306\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 97.3472 - val_loss: 109.9704\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 97.1227 - val_loss: 109.4393\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 96.8606 - val_loss: 109.3518\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 96.6241 - val_loss: 109.1237\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 96.5123 - val_loss: 108.2083\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 96.2272 - val_loss: 110.0754\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 96.2748 - val_loss: 109.4752\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 96.1199 - val_loss: 108.4300\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 95.5703 - val_loss: 108.9597\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 95.3461 - val_loss: 109.4341\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 95.1665 - val_loss: 108.9114\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 94.9262 - val_loss: 108.5411\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 94.8764 - val_loss: 108.5904\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 94.6049 - val_loss: 108.1236\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 94.3660 - val_loss: 108.4300\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 94.0567 - val_loss: 109.5036\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 93.8203 - val_loss: 108.0973\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 93.6148 - val_loss: 107.2560\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 93.6554 - val_loss: 107.5433\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 93.1901 - val_loss: 106.9338\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 93.0912 - val_loss: 106.7361\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 92.6854 - val_loss: 107.4438\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 92.4697 - val_loss: 108.5632\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 92.5165 - val_loss: 107.1826\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 92.0345 - val_loss: 107.9456\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 92.2100 - val_loss: 107.8410\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 91.5777 - val_loss: 106.5597\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 91.5219 - val_loss: 106.8357\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 91.1366 - val_loss: 106.5499\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 90.9368 - val_loss: 106.4255\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 90.7028 - val_loss: 107.1786\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 90.5027 - val_loss: 107.3379\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 90.2600 - val_loss: 106.4705\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 90.2470 - val_loss: 105.3885\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 89.7926 - val_loss: 107.9684\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 90.0242 - val_loss: 106.1934\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 89.3982 - val_loss: 105.4054\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 89.2998 - val_loss: 105.2809\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 89.0620 - val_loss: 106.6775\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 88.8652 - val_loss: 105.1627\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 88.6891 - val_loss: 106.6390\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 88.6555 - val_loss: 105.6137\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 88.3244 - val_loss: 106.3298\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 87.9761 - val_loss: 105.1886\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 87.7635 - val_loss: 104.8131\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 87.5662 - val_loss: 104.4214\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 87.7088 - val_loss: 103.7250\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 87.2356 - val_loss: 105.6105\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 86.9277 - val_loss: 104.5383\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 86.8297 - val_loss: 104.4157\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 86.7880 - val_loss: 105.2195\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 86.2553 - val_loss: 104.5239\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 86.2502 - val_loss: 104.9178\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 85.8610 - val_loss: 103.1481\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 85.7449 - val_loss: 104.0207\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 85.5280 - val_loss: 103.4221\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 85.1371 - val_loss: 104.4040\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 84.9356 - val_loss: 103.2734\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 84.8966 - val_loss: 103.6448\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 84.6759 - val_loss: 103.0672\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 84.2394 - val_loss: 103.8997\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 84.1316 - val_loss: 103.3122\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 83.9196 - val_loss: 103.9352\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 83.7143 - val_loss: 102.4289\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 83.4413 - val_loss: 102.5810\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 83.6857 - val_loss: 102.3598\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 83.1578 - val_loss: 102.9179\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 82.8375 - val_loss: 101.0439\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 82.4721 - val_loss: 102.6057\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 82.5382 - val_loss: 101.0387\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 82.2664 - val_loss: 100.9301\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 81.8231 - val_loss: 100.7758\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 81.6893 - val_loss: 100.6820\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 81.4715 - val_loss: 101.7721\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 81.2984 - val_loss: 100.3867\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 81.0178 - val_loss: 100.5247\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 80.8893 - val_loss: 100.5089\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 80.5992 - val_loss: 100.1837\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 80.4204 - val_loss: 100.7233\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 80.1367 - val_loss: 100.0804\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 80.0853 - val_loss: 98.8070\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 79.7135 - val_loss: 99.6861\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 79.7552 - val_loss: 99.4563\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 79.2687 - val_loss: 97.5450\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 79.0473 - val_loss: 98.1126\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 78.9198 - val_loss: 98.5836\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 78.5721 - val_loss: 97.7637\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 78.3831 - val_loss: 97.6808\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 78.2479 - val_loss: 97.2227\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 77.9143 - val_loss: 96.3732\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 77.6656 - val_loss: 96.9449\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 77.3958 - val_loss: 98.1189\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 77.5323 - val_loss: 97.9560\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 77.3251 - val_loss: 95.2823\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 76.7930 - val_loss: 96.2001\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 76.5360 - val_loss: 96.3403\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 76.3434 - val_loss: 97.1967\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 76.0378 - val_loss: 96.1457\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 75.7765 - val_loss: 95.7665\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 75.4429 - val_loss: 95.9950\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 75.2508 - val_loss: 96.2728\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 74.9713 - val_loss: 94.6664\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 74.8071 - val_loss: 96.6911\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 74.2729 - val_loss: 94.7840\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 73.9905 - val_loss: 94.6089\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 73.7986 - val_loss: 95.0749\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 73.4155 - val_loss: 94.4621\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 73.1723 - val_loss: 95.1988\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 72.8497 - val_loss: 94.6689\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 72.8019 - val_loss: 94.3181\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 72.4243 - val_loss: 94.7594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 72.1265 - val_loss: 94.7992\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 71.5884 - val_loss: 94.1176\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 71.2574 - val_loss: 94.5675\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 71.1232 - val_loss: 94.6623\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 70.7308 - val_loss: 92.9737\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 70.6098 - val_loss: 94.6382\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 70.1143 - val_loss: 92.9061\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 69.9629 - val_loss: 92.4863\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 69.7883 - val_loss: 94.6757\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 69.3578 - val_loss: 92.4138\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 69.3089 - val_loss: 93.1309\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 68.8697 - val_loss: 91.2781\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 68.5795 - val_loss: 93.0995\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 68.3584 - val_loss: 91.8172\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 68.0472 - val_loss: 93.2192\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 67.8033 - val_loss: 91.6763\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 67.5042 - val_loss: 91.4961\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 67.1839 - val_loss: 92.0188\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 66.9673 - val_loss: 91.5196\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 66.7760 - val_loss: 90.7408\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 66.4078 - val_loss: 92.0920\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 66.2140 - val_loss: 89.7196\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 65.9164 - val_loss: 90.7311\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 65.6986 - val_loss: 91.4919\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 65.6385 - val_loss: 91.2061\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 65.3263 - val_loss: 89.2742\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 64.8490 - val_loss: 91.2950\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 64.8102 - val_loss: 89.9486\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 64.3138 - val_loss: 91.6820\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 64.0472 - val_loss: 89.9489\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 63.9843 - val_loss: 89.0859\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 63.6011 - val_loss: 90.3110\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 63.3524 - val_loss: 89.8139\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 63.1114 - val_loss: 90.5369\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 62.8729 - val_loss: 89.7245\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 62.6807 - val_loss: 89.9611\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 62.7157 - val_loss: 88.9211\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 62.2560 - val_loss: 89.3052\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 61.9760 - val_loss: 88.5469\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 61.5968 - val_loss: 88.7797\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 61.4624 - val_loss: 88.5565\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 61.1283 - val_loss: 88.4902\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 60.9752 - val_loss: 87.5325\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 60.9574 - val_loss: 88.7301\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 60.5548 - val_loss: 88.2610\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 60.4163 - val_loss: 86.7282\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 60.0179 - val_loss: 87.9983\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 59.9105 - val_loss: 87.8183\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 59.6975 - val_loss: 88.3654\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 59.3980 - val_loss: 86.9747\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 59.2495 - val_loss: 87.7344\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 59.2096 - val_loss: 86.9584\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 58.9839 - val_loss: 87.2665\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 58.5682 - val_loss: 87.3064\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 58.4704 - val_loss: 86.6613\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 58.2541 - val_loss: 86.1240\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 58.0351 - val_loss: 86.5112\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 58.0662 - val_loss: 85.6113\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 57.6241 - val_loss: 87.6073\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 57.6354 - val_loss: 86.0793\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 57.2582 - val_loss: 86.4675\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 57.0852 - val_loss: 86.1361\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 56.9363 - val_loss: 87.4664\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 56.8048 - val_loss: 86.2383\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 56.6966 - val_loss: 86.6796\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 56.5949 - val_loss: 86.2022\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 56.5397 - val_loss: 87.1039\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 56.3252 - val_loss: 84.7784\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 55.8186 - val_loss: 87.3705\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 55.9855 - val_loss: 87.5308\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 55.4320 - val_loss: 85.7659\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 55.4733 - val_loss: 86.0425\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 55.3623 - val_loss: 86.5426\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 55.0614 - val_loss: 86.1709\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 54.8206 - val_loss: 86.7100\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 54.6487 - val_loss: 85.8570\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 54.3827 - val_loss: 87.5529\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 54.4408 - val_loss: 86.9417\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 54.1482 - val_loss: 86.2359\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 53.9034 - val_loss: 87.5232\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 54.0125 - val_loss: 87.7916\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 53.8055 - val_loss: 86.2149\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 53.4761 - val_loss: 87.5094\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 53.4386 - val_loss: 87.0383\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 53.4450 - val_loss: 86.3586\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 53.0486 - val_loss: 86.7182\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 52.9244 - val_loss: 86.3624\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 52.6232 - val_loss: 88.0581\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 52.5069 - val_loss: 87.6705\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 52.3607 - val_loss: 87.1176\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 52.1421 - val_loss: 88.2342\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 52.0157 - val_loss: 86.8212\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 51.8477 - val_loss: 87.7822\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 51.9966 - val_loss: 87.4679\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 51.6435 - val_loss: 87.5829\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 51.5503 - val_loss: 87.1585\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 51.3323 - val_loss: 87.8972\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 51.2156 - val_loss: 88.9675\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 51.1486 - val_loss: 87.5892\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 51.1365 - val_loss: 89.5577\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 50.6286 - val_loss: 86.7478\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 50.5247 - val_loss: 87.7262\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 50.4776 - val_loss: 88.9036\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 50.3362 - val_loss: 88.4995\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 50.4848 - val_loss: 88.0821\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 49.9656 - val_loss: 89.3727\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 49.8609 - val_loss: 89.3846\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 49.7608 - val_loss: 87.1468\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 49.4538 - val_loss: 90.0583\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 49.3538 - val_loss: 88.2397\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 49.4005 - val_loss: 88.9733\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 49.0789 - val_loss: 87.3421\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 48.9301 - val_loss: 89.7742\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 49.0819 - val_loss: 88.4204\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 48.7618 - val_loss: 89.4019\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 48.6802 - val_loss: 88.6693\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 48.4172 - val_loss: 89.2033\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 48.2974 - val_loss: 89.4604\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 48.1947 - val_loss: 88.7076\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 48.0480 - val_loss: 90.0155\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 48.3223 - val_loss: 89.6537\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 47.8216 - val_loss: 89.5963\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 47.6236 - val_loss: 89.3481\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 47.6450 - val_loss: 88.7262\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 47.6181 - val_loss: 89.4731\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 47.9256 - val_loss: 90.8477\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 47.1619 - val_loss: 88.7601\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 47.0965 - val_loss: 89.3159\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 46.9291 - val_loss: 88.5066\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 46.8289 - val_loss: 91.0728\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 46.6647 - val_loss: 89.6205\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 46.7319 - val_loss: 89.6234\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 46.7823 - val_loss: 89.6282\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 46.5373 - val_loss: 91.3652\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 46.6074 - val_loss: 88.0313\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 46.3294 - val_loss: 89.9099\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 46.2263 - val_loss: 89.0299\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 46.0618 - val_loss: 89.2964\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 45.8881 - val_loss: 88.6721\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 45.7895 - val_loss: 89.5751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 45.7742 - val_loss: 91.4897\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 45.5846 - val_loss: 91.7609\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 45.4191 - val_loss: 90.6444\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 45.2744 - val_loss: 90.0962\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 45.2971 - val_loss: 90.2964\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 45.2829 - val_loss: 90.3183\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 45.0552 - val_loss: 90.5646\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 44.9519 - val_loss: 90.2729\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 45.1532 - val_loss: 91.4755\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 44.7385 - val_loss: 91.2922\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 44.7305 - val_loss: 91.0438\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 44.5667 - val_loss: 91.3934\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 44.5129 - val_loss: 90.9618\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 44.3055 - val_loss: 90.2098\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 44.3471 - val_loss: 90.7452\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 44.1115 - val_loss: 89.9894\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 44.0111 - val_loss: 90.0270\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 44.0506 - val_loss: 92.2690\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 43.8161 - val_loss: 90.2370\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 43.8687 - val_loss: 91.6334\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 43.7971 - val_loss: 90.4499\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 43.7674 - val_loss: 92.2602\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 43.4168 - val_loss: 89.8617\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 43.5283 - val_loss: 92.2306\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 43.3188 - val_loss: 91.3445\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 43.2996 - val_loss: 92.2887\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 43.1578 - val_loss: 90.5537\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 43.0552 - val_loss: 90.9604\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 43.2965 - val_loss: 91.5454\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 42.9102 - val_loss: 91.8586\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 42.9497 - val_loss: 90.5554\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 42.8105 - val_loss: 93.2542\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 42.6810 - val_loss: 90.1369\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 42.6512 - val_loss: 93.7931\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 42.4257 - val_loss: 90.1860\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 42.6757 - val_loss: 90.8375\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 42.5113 - val_loss: 91.6797\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 42.1871 - val_loss: 92.4718\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 42.1886 - val_loss: 90.4504\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 42.6402 - val_loss: 93.4213\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 42.2379 - val_loss: 91.2396\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 42.0034 - val_loss: 91.8745\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 41.8985 - val_loss: 92.4173\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 41.9184 - val_loss: 91.4431\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 41.7024 - val_loss: 92.7560\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 41.6213 - val_loss: 92.1769\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 42.2957 - val_loss: 89.9276\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 42.2750 - val_loss: 94.0467\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 41.4823 - val_loss: 92.6939\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 42.0302 - val_loss: 94.2702\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 41.3696 - val_loss: 92.4903\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 41.1094 - val_loss: 93.2412\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 41.0933 - val_loss: 93.3380\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 41.0572 - val_loss: 92.3479\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 41.1989 - val_loss: 91.8661\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 40.7655 - val_loss: 93.9408\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 40.8796 - val_loss: 92.2104\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 40.8838 - val_loss: 91.3895\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 40.8250 - val_loss: 91.6457\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 40.7360 - val_loss: 91.2558\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 40.5799 - val_loss: 94.4222\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 40.4642 - val_loss: 93.0163\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 40.4087 - val_loss: 91.3131\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 40.4059 - val_loss: 92.5143\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 40.5812 - val_loss: 94.0963\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 40.4949 - val_loss: 93.6626\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 40.2835 - val_loss: 93.9850\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 40.0442 - val_loss: 93.9259\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 40.1326 - val_loss: 92.9447\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 39.9128 - val_loss: 93.2294\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 39.9550 - val_loss: 94.7829\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 39.7753 - val_loss: 93.3410\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 39.7597 - val_loss: 95.1344\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 39.7517 - val_loss: 92.7011\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 39.7913 - val_loss: 95.4549\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 39.6949 - val_loss: 93.9255\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 39.7211 - val_loss: 94.3448\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 39.5371 - val_loss: 92.5142\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 40.0943 - val_loss: 96.2843\n",
      "Epoch 43/50\n",
      "23/23 - 0s - loss: 39.6918 - val_loss: 94.7091\n",
      "Epoch 44/50\n",
      "23/23 - 0s - loss: 39.4150 - val_loss: 93.5062\n",
      "Epoch 45/50\n",
      "23/23 - 0s - loss: 39.2539 - val_loss: 97.2342\n",
      "Epoch 46/50\n",
      "23/23 - 0s - loss: 39.4427 - val_loss: 93.0012\n",
      "Epoch 47/50\n",
      "23/23 - 0s - loss: 39.5227 - val_loss: 94.4592\n",
      "Epoch 48/50\n",
      "23/23 - 0s - loss: 39.3347 - val_loss: 95.4135\n",
      "Epoch 49/50\n",
      "23/23 - 0s - loss: 39.1137 - val_loss: 94.0535\n",
      "Epoch 50/50\n",
      "23/23 - 0s - loss: 38.9248 - val_loss: 96.0157\n",
      "Epoch 1/50\n",
      "23/23 - 0s - loss: 39.0117 - val_loss: 95.8439\n",
      "Epoch 2/50\n",
      "23/23 - 0s - loss: 38.9013 - val_loss: 95.4400\n",
      "Epoch 3/50\n",
      "23/23 - 0s - loss: 38.8594 - val_loss: 96.3828\n",
      "Epoch 4/50\n",
      "23/23 - 0s - loss: 38.9586 - val_loss: 97.1914\n",
      "Epoch 5/50\n",
      "23/23 - 0s - loss: 38.7506 - val_loss: 94.9062\n",
      "Epoch 6/50\n",
      "23/23 - 0s - loss: 38.7559 - val_loss: 96.9088\n",
      "Epoch 7/50\n",
      "23/23 - 0s - loss: 38.5701 - val_loss: 97.7201\n",
      "Epoch 8/50\n",
      "23/23 - 0s - loss: 38.6719 - val_loss: 95.3658\n",
      "Epoch 9/50\n",
      "23/23 - 0s - loss: 38.5438 - val_loss: 96.1028\n",
      "Epoch 10/50\n",
      "23/23 - 0s - loss: 38.4952 - val_loss: 94.3297\n",
      "Epoch 11/50\n",
      "23/23 - 0s - loss: 38.3563 - val_loss: 97.1238\n",
      "Epoch 12/50\n",
      "23/23 - 0s - loss: 38.2491 - val_loss: 95.9381\n",
      "Epoch 13/50\n",
      "23/23 - 0s - loss: 38.6229 - val_loss: 94.8926\n",
      "Epoch 14/50\n",
      "23/23 - 0s - loss: 38.2163 - val_loss: 96.7662\n",
      "Epoch 15/50\n",
      "23/23 - 0s - loss: 38.1696 - val_loss: 96.8674\n",
      "Epoch 16/50\n",
      "23/23 - 0s - loss: 38.2818 - val_loss: 96.6280\n",
      "Epoch 17/50\n",
      "23/23 - 0s - loss: 38.2728 - val_loss: 96.6307\n",
      "Epoch 18/50\n",
      "23/23 - 0s - loss: 38.0273 - val_loss: 97.0070\n",
      "Epoch 19/50\n",
      "23/23 - 0s - loss: 38.0692 - val_loss: 97.2747\n",
      "Epoch 20/50\n",
      "23/23 - 0s - loss: 37.9902 - val_loss: 97.1353\n",
      "Epoch 21/50\n",
      "23/23 - 0s - loss: 37.9538 - val_loss: 99.7059\n",
      "Epoch 22/50\n",
      "23/23 - 0s - loss: 38.1671 - val_loss: 98.0552\n",
      "Epoch 23/50\n",
      "23/23 - 0s - loss: 37.9071 - val_loss: 97.0514\n",
      "Epoch 24/50\n",
      "23/23 - 0s - loss: 37.7816 - val_loss: 97.1847\n",
      "Epoch 25/50\n",
      "23/23 - 0s - loss: 37.7463 - val_loss: 97.0870\n",
      "Epoch 26/50\n",
      "23/23 - 0s - loss: 37.5829 - val_loss: 98.6532\n",
      "Epoch 27/50\n",
      "23/23 - 0s - loss: 37.6286 - val_loss: 97.4887\n",
      "Epoch 28/50\n",
      "23/23 - 0s - loss: 37.6612 - val_loss: 98.9099\n",
      "Epoch 29/50\n",
      "23/23 - 0s - loss: 37.5529 - val_loss: 97.1002\n",
      "Epoch 30/50\n",
      "23/23 - 0s - loss: 37.4047 - val_loss: 98.3443\n",
      "Epoch 31/50\n",
      "23/23 - 0s - loss: 37.5046 - val_loss: 98.7276\n",
      "Epoch 32/50\n",
      "23/23 - 0s - loss: 37.8504 - val_loss: 96.2983\n",
      "Epoch 33/50\n",
      "23/23 - 0s - loss: 37.6896 - val_loss: 99.3701\n",
      "Epoch 34/50\n",
      "23/23 - 0s - loss: 37.3248 - val_loss: 96.6483\n",
      "Epoch 35/50\n",
      "23/23 - 0s - loss: 37.4745 - val_loss: 97.5078\n",
      "Epoch 36/50\n",
      "23/23 - 0s - loss: 37.2878 - val_loss: 98.7086\n",
      "Epoch 37/50\n",
      "23/23 - 0s - loss: 37.3286 - val_loss: 99.8966\n",
      "Epoch 38/50\n",
      "23/23 - 0s - loss: 37.2829 - val_loss: 98.0070\n",
      "Epoch 39/50\n",
      "23/23 - 0s - loss: 37.1742 - val_loss: 99.2848\n",
      "Epoch 40/50\n",
      "23/23 - 0s - loss: 37.2866 - val_loss: 99.5450\n",
      "Epoch 41/50\n",
      "23/23 - 0s - loss: 37.0235 - val_loss: 97.3684\n",
      "Epoch 42/50\n",
      "23/23 - 0s - loss: 37.1071 - val_loss: 100.1905\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1341ffaaa89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmses_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-1341ffaaa89d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmses_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3005\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   3008\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mses_b = []\n",
    "\n",
    "for _ in range(50):\n",
    "    model = classificaiton_model\n",
    "    mses_b.append(model.fit(predictors_norm, target, validation_split=0.3, epochs=50, verbose=2).history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Increate the number of epochs (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part B **but use 100 epochs this time for training.**\n",
    "\n",
    "**How does the mean of the mean squared errors compare to that from Step B?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Increase the number of hidden layers (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "**How does the mean of the mean squared errors compare to that from Step B?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
